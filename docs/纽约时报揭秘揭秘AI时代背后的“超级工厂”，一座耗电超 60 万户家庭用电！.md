# 纽约时报揭秘揭秘AI时代背后的“超级工厂”，一座耗电超 60 万户家庭用电！
[纽约时报揭秘揭秘AI时代背后的“超级工厂”，一座耗电超 60 万户家庭用电！](https://mp.weixin.qq.com/s/ILjsENw2Y0N5JXAHrjUD9g) 

 当今推动人工智能（A.I.）发展的“发动机”，是一种叫做 **GPU** 的小型硅芯片（图形处理器）。它最初是为了视频游戏而设计的。

现在，各大科技公司正把 GPU（因非常适合运行 A.I. 所需的大量计算）密集地装进 **专用计算机** 里。

由此诞生了一种新型“超级计算机”——在被称为 **数据中心** 的大型建筑里，部署多达 10 万块以上的芯片，通过连接在一起的方式，全力训练和运行功能强大的人工智能系统。

所有这些计算能力都伴随着巨大的能耗成本。ChatGPT 的开发者 OpenAI 希望建造大约 5 座设施，这些设施加在一起所消耗的电量，将超过马萨诸塞州约 300 万户家庭的用电量。

随着科技公司不断追逐 A.I. 的梦想，这些 **数据中心** 已在美国各地涌现……

……并且还在向 **全球** 扩散，迫使科技巨头到处寻找电力和水源，用于为数据中心供电与冷却，以防这些芯片因自身产生的热量而烧毁。

对计算机的这种根本性变革，是自万维网早期以来最重大的一次。正如 20 世纪 90 年代公司为适应新兴的互联网商业模式而彻底重塑计算机系统一样，如今从微小元器件到大型机房与能源供应的方式，也都在为适应人工智能而重新构建。

其实，大型科技公司在过去二十多年里，就已经在全世界各地建造数据中心，用来容纳处理海量网络流量的计算机，比如搜索引擎、电子邮件服务和电商网站。

但与正在到来的这一波 A.I. 数据中心相比，之前的那些显得“轻量”得多。2006 年，谷歌在俄勒冈州达尔斯（The Dalles）建立了它的首个数据中心\[1\]，当时估计花费了 6 亿美元。而 2025 年 1 月，OpenAI 和几个合作伙伴宣布计划\[2\] 投资大约 1000 亿美元建设新的数据中心，首批在德克萨斯州选址。随后还将陆续在美国各地投入额外 4000 亿美元兴建更多设施。

这场计算革命所影响的远不止科技本身，也包括金融、能源以及各地社区。私募股权公司正将资金大量投入数据中心企业；电工也在蜂拥前往\[3\] 这些数据中心项目所在地寻求工作机会；而在某些地方，当地居民对于这些项目感到抵触\[4\]，担心弊大于利。

目前，科技公司需要的计算能力和电力几乎超过了世界所能供应的水平。OpenAI 希望筹集数千亿美元，在中东建设芯片制造工厂\[5\]。谷歌和亚马逊最近达成协议，计划建造并部署新一代核反应堆\[6\]。而且他们希望一切都能尽快完成。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/Sib7IezOlBcvJyGBT959LianqlQOEcQVyac9bZgK0M7iaxbF9VOknE9QYsMUHYOuqib9AaJLxCqYsDBbU6xm09vtoA/640?wx_fmt=jpeg&from=appmsg)

一排装载在蓝色主板上的电脑芯片（原文插图）

> 谷歌的 A.I. 芯片与电路板。为构建旗下聊天机器人和其他 A.I. 技术，谷歌需要大量此类芯片。

在 2024 年 12 月，一家名叫 DeepSeek 的中国小公司声称，利用远少于业界预期数量的芯片，就打造出了世界上最强大的 A.I. 系统之一\[7\]，颠覆了人们\[8\] 对硅谷疯狂投入是否物有所值的质疑。

然而，美国科技巨头们似乎并不为所动。他们的远大目标是打造“通用人工智能”（A.G.I.）——即能完成任何人类大脑可胜任任务的机器。他们依然相信，为了达到这一点，庞大的计算能力必不可少。

亚马逊、Meta、微软以及谷歌母公司 Alphabet 近期透露\[9\]，他们今年的资本开支（主要用于建设数据中心）合计可超过 3200 亿美元，几乎是两年前的一倍多。

《纽约时报》记者前往加利福尼亚州、犹他州、德克萨斯州和俄克拉何马州的五处新建数据中心园区，并采访了 50 多位高管、工程师、企业家和电工，来呈现科技行业对这类全新计算方式的巨大渴求。

“原本可能需要十年才能完成的事，如今在两年内就压缩完成了。”谷歌首席执行官桑达尔·皮查伊（Sundar Pichai）在接受《纽约时报》采访时说，“A.I. 就像催化剂。”

* * *

为 A.I. 而生的新型计算机芯片
-----------------

推动这次计算机飞跃的核心，是一种极小的要素：名为图形处理器（GPU）的专用芯片。

像英伟达（Nvidia）这样的硅谷芯片制造商，最初为视频游戏设计了 GPU。然而，GPU 在执行神经网络所需的大规模数学运算方面非常在行。神经网络可以通过分析海量数据来“学习技能”，这也是当今聊天机器人和各种先进 A.I. 技术的基础。

### A.I. 模型是如何被“训练”的

神经网络通过分析海量数据学会区分信息，这个过程也被称为机器学习。下面这个示例展示了 A.I. 模型如何基于大量花朵图片，学习识别一朵花的图像。

1. **提供参考素材**  
A.I. 模型的训练需要分析大量参考数据——这是一个既耗时又需要巨大计算量的过程。

1.  ![](https://mmbiz.qpic.cn/sz_mmbiz_gif/Sib7IezOlBcvJyGBT959LianqlQOEcQVyaJhUNyFCJ2voABl4NuibG5cChsNmGqxnULTpdLTjOwrc4pyicjKkibKLTQ/640?wx_fmt=gif&from=appmsg)
    

2. **映射数据**  
将图片分解成像素，并按照不同标签进行分组，便于模型在后续识别时调用。

1.  ![](https://mmbiz.qpic.cn/sz_mmbiz_gif/Sib7IezOlBcvJyGBT959LianqlQOEcQVya0NlZ0YTU15liaZYuLtTCiaCacMQz8awvABYicibibB89J80GCKia8I7n8kvw/640?wx_fmt=gif&from=appmsg)
    

3. **对比并预测**  
模型能在数百万张图片中找出共同模式，从而可以自主识别不同对象。

1.  ![](https://mmbiz.qpic.cn/sz_mmbiz_gif/Sib7IezOlBcvJyGBT959LianqlQOEcQVya3DD44VqBlI7Zicq1MR0aT09gHuzz5z2DUJbLbw5hib1l2uicLO64uLyLA/640?wx_fmt=gif&from=appmsg)
    
      
    

过去，计算机主要依赖被称为中央处理器（CPU）的芯片。CPU 什么都能做，包括运行神经网络所需的简单数学计算。

但 GPU 更能干同样的工作——而且速度更快。在同一时刻，传统芯片只能做一次计算，而 GPU 却可以同时进行成千上万次。计算机科学家把这种能力称为“并行处理（parallel processing）”，这使神经网络能处理更多数据。

“它们跟用来提供网页的芯片有非常大区别。”Together AI（一家科技咨询公司）的首席执行官 Vipul Ved Prakash 说，“GPU 能在同一时间完成数百万次运算，从而让机器有‘思考’问题的能力。”

因此，科技公司开始使用越来越多的 GPU 来训练功能越来越强的 A.I.。

### CPU 与 GPU 的差异

  

| **传统 CPU 计算（视频左）** | **GPU 并行计算（视频右）** |
| --- | --- |
| 

数据按顺序依次处理，前一个任务完成后才进行下一个任务。

 | 

通过多处理器并行把任务切分成更小的部分，同时执行多个计算，从而大幅加快速度。

 |

随着使用需求的提升，英伟达也在对其 GPU 进行改造，使其更适合 A.I.，在每块芯片中塞进更多晶体管，以便在每秒进行更多计算。2013 年，谷歌也开始自行研制 A.I. 芯片\[10\]。

这些谷歌与英伟达的芯片，并非用于运行操作系统，也不能在像 Windows 笔记本或 iPhone 上承担各种应用功能。但它们与其他硬件协同工作时，却能极大加速 A.I. 的发展。

“过去的模式大概延续了 50 年左右。”负责谷歌 A.I. 芯片项目的工程师 Norm Jouppi 表示，“如今，我们有了完全不同的做事方式。”

* * *

芯片放得越近，速度就越快
------------

不仅仅是芯片本身发生了变化。为了让 GPU 发挥最大的性能，科技公司必须想方设法加快数据在各个芯片之间的传输速度。

“每块 GPU 都需要和其他所有 GPU 之间进行高速通信。”Cirrascale Cloud Services 的首席技术官 Dave Driggers 如此描述。这家公司在德克萨斯州奥斯汀运营一家数据中心，为知名 A.I. 研究机构艾伦人工智能研究所（Allen Institute for Artificial Intelligence）提供计算服务。

芯片彼此之间距离越近，数据传输就越快。所以各公司都在同一个数据中心里塞进尽可能多的芯片，并且研发新的硬件和线缆，来加快芯片与芯片之间的数据流。

  

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/Sib7IezOlBcvJyGBT959LianqlQOEcQVyaliaiaZcCicAvqezmtKHfYjvWdIrs0gawkHcYZVnKk88GtEpOr9Nn7glwA/640?wx_fmt=jpeg&from=appmsg)

坐落在犹他州湖山（Lake Mountains）山脚下的 Meta Eagle Mountain 数据中心，远处山峰上有积雪（原文插图）

> Meta 的 Eagle Mountain 数据中心，位于盐湖城以南的一个山谷中。这栋大楼是在 A.I. 热潮爆发后破土动工的。

这也改变了数据中心的运作方式——传统上，它们就是大型厂房，里面整齐摆放着一排排的服务器机架。

2021 年，在 A.I. 热潮到来之前，Meta 曾在盐湖城以南约一个小时车程的地方新建了两座数据中心，并正在那里建设另外三座。这些设施——每栋建筑的占地面积相当于把帝国大厦横放在沙漠上——最初是为支撑该公司社交媒体应用（如 Facebook、Instagram）所需的网络服务。

但是在 2022 年 OpenAI 推出 ChatGPT\[11\] 后，Meta 重新审视了它的 A.I. 计划。公司需要在一座全新的数据中心里塞进数千块 GPU，才能支撑训练单个神经网络可能长达数周甚至数月的计算需求，进而推进 A.I. 的研发。

“所有设备必须像一个‘数据中心级超级计算机’那样统一协作。”Meta 数据中心副总裁 Rachel Peterson 说，“这对基础设计是全新的挑战。”

几个月内，Meta 又动工兴建了第六座与第七座犹他州数据中心，规模均达 70 万平方英尺。在这些数据中心里，技术人员把专门用于训练 A.I. 的硬件（里面装满 GPU 的设备）一台台装到机架上，而这些 GPU 服务器每台价格就可能高达数万美元。

2023 年，Meta 计入了 42 亿美元的重组费用\[12\]，部分原因就是要调整未来许多数据中心项目的设计，以迎接 A.I. 需求。事实上，不止 Meta，一股行业大潮正在兴起。

* * *

A.I. 机器需要更多电力——多得多
------------------

把新的数据中心装满 GPU 意味着新的电力需求——而且需求量极大。

2023 年 12 月，Cirrascale 租下了奥斯汀一处占地 13.9 万平方英尺的传统数据中心。原本，这里可用约 5 兆瓦电力，足以为约 3600 户美国家庭供电。那时，里面有 80 行左右的机架，用来放置常规的 CPU 服务器。

现在，为了满足 A.I. 需要，Cirrascale 拆掉了旧设备，用 GPU 系统来替换。结果，原先给整幢建筑供电的 5 兆瓦，如今只够带动其中大约 8 到 10 行装满 GPU 的机架。

该数据中心可以向当地电网申请升级到约 50 兆瓦，但即便如此，也无法全部换成 GPU。而即使有 50 兆瓦的负荷能力，对 A.I. 数据中心来说仍算小规模。相比之下，OpenAI 的目标是建设约 5 座数据中心，总耗电量将超过大约 300 万户美国家庭\[13\] 的总和。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/Sib7IezOlBcvJyGBT959LianqlQOEcQVyaejEicvpQHkyb7hB59Vg9Z3eDGxhgI7jjBAA7QFSAO5JQEj2Dv8IMiavw/640?wx_fmt=jpeg&from=appmsg)

一张位于德州奥斯汀 Cirrascale 数据中心内部的照片，前景是空荡的白色房间，远处有机架设备（原文插图）

> Cirrascale 在德州奥斯汀的这个数据中心，最大可从电网获取 5 兆瓦电力，但这只能为 8 到 10 行 GPU 服务器供电。

这不仅因为数据中心里服务器更密集，还因为支撑 A.I. 的芯片本身需要更多电力。普通 CPU 功率大约在 250 到 500 瓦之间，而 GPU 则可以高达 1000 瓦。

建设数据中心时最终要与当地电力公司“谈判”：它能提供多少电力？电费多少？如果需要投入巨资升级电网设备，又由谁出钱？

2023 年，美国数据中心的用电量约占全国总耗电的 4.4%，超过了加密货币“挖矿”中心用电量的两倍。根据美国能源部 2023 年 12 月发布的报告，这一数字到 2028 年可能会增加三倍。

### A.I. 数据中心的用电量

能源部下属的劳伦斯伯克利国家实验室（Lawrence Berkeley National Laboratory）推算，专门用于 A.I. 的数据中心，到 2028 年的用电量可能高达 326 太瓦时（TWh），几乎是 2023 年用电量的 8 倍。

![](https://mmbiz.qpic.cn/sz_mmbiz_png/Sib7IezOlBcvJyGBT959LianqlQOEcQVyaerVich60f1um8IH1L9Av9D53QO72CWBkansPjQHxzz4aw0JppttYP8g/640?wx_fmt=png&from=appmsg)

数据来源：劳伦斯伯克利国家实验室，美国能源部

“时间才是现在行业里最宝贵的资源。”负责这份报告的研究员 Arman Shehabi 说，“大家都在抢着建，我短期内看不到放缓的迹象。”

在美国的部分地区，数据中心运营商正遭遇电力短缺。比如全球最大数据中心聚集地北弗吉尼亚州（这里有通往欧洲的海底电缆），可供调用的电力几乎被消耗殆尽。

一些 A.I. 巨头转而寻求核能。微软正在重启\[14\] 位于宾夕法尼亚州的三里岛（Three Mile Island）核电站。

也有公司另辟蹊径。埃隆·马斯克（Elon Musk）和他的 A.I. 创企 xAI 最近在孟菲斯自己安装了燃气轮机\[15\]，没有追求清洁能源，只求更快落地。

“现在我的对话主题已经不是‘要到哪里搞到最先进的芯片’，而是‘哪儿能弄到足够的电力’。”A.I. 风险投资机构 Radical Ventures 的合伙人 David Katz 说。

* * *

A.I. 散热太高，只有水才能降温
-----------------

这些密度极高的 A.I. 系统还带来了另一场变革：全新的冷却方式。

A.I. 系统运转时会产生大量热量。当空气从服务器机架的前方经过，横穿计算芯片后，就会变得很热。在 Cirrascale 奥斯汀的数据中心，一台机架前侧温度约 71.2 华氏度（约 21.8 摄氏度），后方则达到了 96.9 华氏度（约 36 摄氏度）。

如果机架无法及时降温，整台机器，甚至整个数据中心都可能面临起火危险。

在俄克拉何马州东北角的普赖尔镇（Pryor）附近，谷歌大规模地解决了这个问题。

这里宽阔平坦的草地上矗立着 13 座谷歌数据中心大楼。整个园区容纳数以万计的服务器机架，电力从一座座金属铁塔和电缆输送站大量涌入，功率以百兆瓦计。为了防止机架过热，谷歌在 13 座大楼里都安装了冷却水管。

过去，谷歌的数据中心通常把水管敷设在机架之间的通道里，让冷水流经管道，吸收四周空气中的热量。然而，当机架里布满 A.I. 芯片后，水管距离芯片太远，不足以吸走多余热量。

### 传统数据中心

![](https://mmbiz.qpic.cn/sz_mmbiz_png/Sib7IezOlBcvJyGBT959LianqlQOEcQVyaRr50ZVvia4ytbeibWPeATjRsuDYQ7qEbBP4eesmsJCibWpUiaxfI5Ak2EQ/640?wx_fmt=png&from=appmsg)

现在，谷歌让水管直接贴近芯片。只有这样，水才能真正吸走热量，保证芯片安全运行。

### A.I. 数据中心

![](https://mmbiz.qpic.cn/sz_mmbiz_png/Sib7IezOlBcvJyGBT959LianqlQOEcQVyaCG6e7KP1ibxWGnCZF8kmL2zC7cbOT0uuSV915Puz57pWr8NXwNicicdbg/640?wx_fmt=png&from=appmsg)

在装满电子设备的地方跑水管有风险：一旦漏水，就可能造成重大损失。为降低风险，谷歌会给水中添加不导电的化学物质，减少芯片的损坏可能性。

水吸收完热量后，还得再冷却下来。通常做法是在数据中心屋顶加装巨大冷却塔。部分水在此蒸发，带走热量，就像人出汗后汗液蒸发带走热量一样。

“我们把它称作‘自然免费冷却’，在清晨干燥、温度较低的环境下，水会自然蒸发降温。”谷歌数据中心副总裁 Joe Kava 介绍。

![](https://mmbiz.qpic.cn/sz_mmbiz_png/Sib7IezOlBcvJyGBT959LianqlQOEcQVya4T7lzDGA6yz4vTHosuJQJDHou4Z8HTLfOLCMAxZFviakCYiao4sicR4AA/640?wx_fmt=png&from=appmsg)

谷歌数据中心内部，堆满了使用谷歌自研 A.I. 芯片的服务器。

但这也意味着需要源源不断地补充新水来维持循环，对当地供水造成压力。2023 年，谷歌数据中心消耗了 61 亿加仑的水，比前一年增长 17%。在经常面临干旱的加利福尼亚州，有超过 250 个数据中心每年会消耗大量水，当地官员已对此发出警示\[16\]。

一些公司，比如 Cirrascale，会采用大型冷水机（本质上是空调）来冷却循环水，从而几乎可以 100% 回收冷却水，不会大量消耗当地水资源，但这样会耗费更多电力。

目前，这一切都还只是开端。去年，谷歌在南卡罗来纳州、印第安纳州、密苏里州等地又开工兴建了 11 座新数据中心。Meta 也宣布在路易斯安那州 Richland Parish 建造新的数据中心，面积之大足以覆盖纽约中央公园、中城曼哈顿、格林威治村和下东区等区域的总和。

“这是 A.I. 决定性的一年，”Meta 首席执行官马克·扎克伯格（Mark Zuckerberg）在今年 1 月的一则 Facebook 帖子\[17\] 中写道，“让我们投入建设吧！”

#### 引用链接

`[1]` 首个数据中心:_https://www.nytimes.com/2006/06/14/technology/14search.html_  
`[2]`宣布计划:_https://www.nytimes.com/2025/02/08/technology/sam-altman-elon-musk-trump.html_  
`[3]`电工也在蜂拥前往:_https://www.nytimes.com/2024/12/25/technology/ai-data-centers-electricians.html_  
`[4]`对于这些项目感到抵触:_https://www.nytimes.com/2024/10/29/technology/data-center-peculiar-missouri.html_  
`[5]`建设芯片制造工厂:_https://www.nytimes.com/2024/09/25/business/openai-plan-electricity.html_  
`[6]`建造并部署新一代核反应堆:_https://www.nytimes.com/2024/10/16/business/energy-environment/amazon-google-microsoft-nuclear-energy.html_  
`[7]`最强大的 A.I. 系统之一:_https://www.nytimes.com/2025/01/23/technology/deepseek-china-ai-chips.html_  
`[8]`颠覆了人们:_https://www.nytimes.com/2025/01/27/technology/what-is-deepseek-china-ai.html_  
`[9]`透露:_https://www.nytimes.com/2025/02/08/technology/deepseek-data-centers-ai.html_  
`[10]`自行研制 A.I. 芯片:_https://www.nytimes.com/2017/09/16/technology/chips-off-the-old-block-computers-are-taking-design-cues-from-human-brains.html_  
`[11]`OpenAI 推出 ChatGPT:_https://www.nytimes.com/2022/12/10/technology/ai-chat-bot-chatgpt.html_  
`[12]`计入了 42 亿美元的重组费用:_https://www.nytimes.com/2023/02/01/technology/meta-restructuring-charge.html_  
`[13]`超过大约 300 万户美国家庭:_https://www.nytimes.com/2025/02/08/technology/sam-altman-elon-musk-trump.html_  
`[14]`正在重启:_https://www.nytimes.com/2024/10/30/business/energy-environment/three-mile-island-nuclear-energy.html_  
`[15]`安装了燃气轮机:_https://www.npr.org/2024/09/11/nx-s1-5088134/elon-musk-ai-xai-supercomputer-memphis-pollution_  
`[16]`已对此发出警示:_https://www.sacbee.com/opinion/op-ed/article297294554.html_  
`[17]`Facebook 帖子:_https://www.facebook.com/zuck/posts/pfbid0219ude255AKkmk4JAueXZeZ9zpjNYio2tBkd7bNmCaRbJ6iJaVVjypUgDg78CNdq5l_